{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "CQFqYxle3xfs",
      "metadata": {
        "id": "CQFqYxle3xfs"
      },
      "source": [
        "# MultiMAE: Multi-modal Multi-task Masked Autoencoders\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YNrydfP6g2zV",
      "metadata": {
        "id": "YNrydfP6g2zV"
      },
      "source": [
        "**Important:** This notebook requires a GPU for installing certain dependencies. Let's see which one we got here:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zrv-ZKGG3i9Q",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrv-ZKGG3i9Q",
        "outputId": "ceebd0d7-d3b2-47c7-e14c-4bb543f7fa5d"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "uIv8bdqZ37fj",
      "metadata": {
        "id": "uIv8bdqZ37fj"
      },
      "source": [
        "## 1 Install dependencies\n",
        "\n",
        "These cells download the MultiMAE code base, as well as the DPT and Mask2Former repositories that are used to pseudo label RGB images.\n",
        "\n",
        "First, we need to downgrade PyTorch to version 1.10.0 due to compatibility issues with Detectron2. Make sure to restart the runtime once after reinstalling PyTorch, and once after installing all other packages."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zb32NSYljwZ7",
      "metadata": {
        "id": "zb32NSYljwZ7"
      },
      "source": [
        "### 1.1 Downgrade PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "aaGp2w6LfYJv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaGp2w6LfYJv",
        "outputId": "52ac9a52-cfa3-4c9e-e43d-f9c52cab9069"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: torch 1.10.0\n",
            "Uninstalling torch-1.10.0:\n",
            "  Successfully uninstalled torch-1.10.0\n",
            "Found existing installation: torchvision 0.11.2\n",
            "Uninstalling torchvision-0.11.2:\n",
            "  Successfully uninstalled torchvision-0.11.2\n",
            "Found existing installation: torchaudio 0.10.1\n",
            "Uninstalling torchaudio-0.10.1:\n",
            "  Successfully uninstalled torchaudio-0.10.1\n",
            "\u001b[33mWARNING: Skipping torchtext as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.10.0+cu113\n",
            "  Using cached https://download.pytorch.org/whl/cu113/torch-1.10.0%2Bcu113-cp38-cp38-linux_x86_64.whl (1821.4 MB)\n",
            "Collecting torchvision==0.11.0+cu113\n",
            "  Using cached https://download.pytorch.org/whl/cu113/torchvision-0.11.0%2Bcu113-cp38-cp38-linux_x86_64.whl (21.8 MB)\n",
            "Collecting torchaudio==0.10.0\n",
            "  Using cached https://download.pytorch.org/whl/rocm4.1/torchaudio-0.10.0%2Brocm4.1-cp38-cp38-linux_x86_64.whl (2.7 MB)\n",
            "Requirement already satisfied: typing-extensions in /home/chunwei/miniconda3/envs/flight/lib/python3.8/site-packages (from torch==1.10.0+cu113) (4.5.0)\n",
            "Requirement already satisfied: numpy in /home/chunwei/miniconda3/envs/flight/lib/python3.8/site-packages (from torchvision==0.11.0+cu113) (1.23.1)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /home/chunwei/miniconda3/envs/flight/lib/python3.8/site-packages (from torchvision==0.11.0+cu113) (9.4.0)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "Successfully installed torch-1.10.0+cu113 torchaudio-0.10.0+rocm4.1 torchvision-0.11.0+cu113\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip uninstall -y torch torchvision torchaudio torchtext\n",
        "%pip install torch==1.10.0+cu113 torchvision==0.11.0+cu113 torchaudio==0.10.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "JYcdEMrzj7nt",
      "metadata": {
        "id": "JYcdEMrzj7nt"
      },
      "source": [
        "### 1.2 Install dependencies\n",
        "\n",
        "**Important**: Before running the following cells, please restart the runtime using the menu bar entries `Runtime > Restart runtime`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7127bd8a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7127bd8a",
        "outputId": "11fd8ca3-4a13-4ae5-feaf-b4579501efeb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/chunwei/miniconda3/envs/flight/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch:  1.10 ; cuda:  11.3\n",
            "Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/11.3/torch1.10/index.html\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement detectron2 (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for detectron2\u001b[0m\u001b[31m\n",
            "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.version.cuda\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "## Install detectron2 that matches the above pytorch version\n",
        "## See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
        "%pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/$CUDA_VERSION/torch$TORCH_VERSION/index.html\n",
        "\n",
        "## In case you have troubles with Detectron2, consider installing it from source instead. This takes a few minutes.\n",
        "#!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebe8dmf7duNj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebe8dmf7duNj",
        "outputId": "96195ecb-717b-41b9-b470-113f7a19352b"
      },
      "outputs": [],
      "source": [
        "# clone and install Mask2Former\n",
        "# !git clone https://github.com/facebookresearch/Mask2Former.git\n",
        "\n",
        "%cd ../../Mask2Former\n",
        "!pwd\n",
        "\n",
        "%pip install -U opencv-python\n",
        "%pip install git+https://github.com/cocodataset/panopticapi.git\n",
        "\n",
        "%cd mask2former/modeling/pixel_decoder/ops\n",
        "!python setup.py build install\n",
        "%cd ../.."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LsJtsT_M_NCN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsJtsT_M_NCN",
        "outputId": "ccf68bbe-59c7-44ff-ad13-fd5a6ae72e72"
      },
      "outputs": [],
      "source": [
        "# Clone Dense Prediction Transformer repository\n",
        "# !git clone https://github.com/isl-org/DPT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "USfgWItad1bs",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USfgWItad1bs",
        "outputId": "a7cb2a53-94d3-4a46-dded-162c4de9b8ce"
      },
      "outputs": [],
      "source": [
        "# Clone MultiMAE repository\n",
        "# !git clone https://github.com/EPFL-VILAB/MultiMAE\n",
        "%pip install timm==0.4.12\n",
        "%pip install einops==0.3.2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OwzkhnaeAP8M",
      "metadata": {
        "id": "OwzkhnaeAP8M"
      },
      "source": [
        "## 2 Imports and model setup\n",
        "\n",
        "**Important**: Before running the following cells, please restart the runtime **again** using the menu bar entries `Runtime > Restart runtime`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qEAL1hmAkY-A",
      "metadata": {
        "id": "qEAL1hmAkY-A"
      },
      "source": [
        "###Â 2.1 Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7cfc6a1",
      "metadata": {
        "id": "d7cfc6a1"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"./Mask2Former\")\n",
        "sys.path.append(\"./DPT\")\n",
        "sys.path.append(\"./MultiMAE\")\n",
        "\n",
        "# To supress DPT and Mask2Former warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "from functools import partial\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms.functional as TF\n",
        "from torchvision import datasets, transforms\n",
        "from einops import rearrange\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "\n",
        "# Mask2Former and detectron2 dependencies for semantic segmentation pseudo labeling\n",
        "from detectron2.utils.visualizer import ColorMode, Visualizer\n",
        "from detectron2.data import MetadataCatalog\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.projects.deeplab import add_deeplab_config\n",
        "coco_metadata = MetadataCatalog.get(\"coco_2017_val_panoptic\")\n",
        "from mask2former import add_maskformer2_config\n",
        "\n",
        "# DPT dependencies for depth pseudo labeling\n",
        "from dpt.models import DPTDepthModel\n",
        "\n",
        "from multimae.models.input_adapters import PatchedInputAdapter, SemSegInputAdapter\n",
        "from multimae.models.output_adapters import SpatialOutputAdapter\n",
        "from multimae.models.multimae import pretrain_multimae_base\n",
        "from multimae.utils.data_constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
        "\n",
        "torch.set_grad_enabled(False)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ChHY7ibfkfTq",
      "metadata": {
        "id": "ChHY7ibfkfTq"
      },
      "source": [
        "### 2.2 Pseudo labeling model setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fXv_X05zEekt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXv_X05zEekt",
        "outputId": "49a9c3ff-e743-4cb7-854a-b71678ca435c"
      },
      "outputs": [],
      "source": [
        "# Initialize Omnidata depth model\n",
        "\n",
        "!wget https://datasets.epfl.ch/vilab/iccv21/weights/omnidata_rgb2depth_dpt_hybrid.pth -P pretrained_models\n",
        "\n",
        "omnidata_ckpt = torch.load('./pretrained_models/omnidata_rgb2depth_dpt_hybrid.pth', map_location='cpu')\n",
        "depth_model = DPTDepthModel()\n",
        "depth_model.load_state_dict(omnidata_ckpt)\n",
        "depth_model = depth_model.to(device).eval()\n",
        "\n",
        "def predict_depth(img):\n",
        "  depth_model_input = (img.unsqueeze(0) - 0.5) / 0.5\n",
        "  return depth_model(depth_model_input.to(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sw8GTaIIivc5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sw8GTaIIivc5",
        "outputId": "ea43c069-695d-42ec-eeff-bc7095829740"
      },
      "outputs": [],
      "source": [
        "# COCO Mask2Former\n",
        "\n",
        "cfg = get_cfg()\n",
        "add_deeplab_config(cfg)\n",
        "add_maskformer2_config(cfg)\n",
        "cfg.merge_from_file(\"../Mask2Former/configs/coco/panoptic-segmentation/swin/maskformer2_swin_small_bs16_50ep.yaml\")\n",
        "cfg.MODEL.WEIGHTS = 'https://dl.fbaipublicfiles.com/maskformer/mask2former/coco/panoptic/maskformer2_swin_small_bs16_50ep/model_final_a407fd.pkl'\n",
        "cfg.MODEL.MASK_FORMER.TEST.SEMANTIC_ON = True\n",
        "cfg.MODEL.MASK_FORMER.TEST.INSTANCE_ON = True\n",
        "cfg.MODEL.MASK_FORMER.TEST.PANOPTIC_ON = True\n",
        "semseg_model = DefaultPredictor(cfg)\n",
        "\n",
        "def predict_semseg(img):\n",
        "  return semseg_model(255*img.permute(1,2,0).numpy())['sem_seg'].argmax(0)\n",
        "\n",
        "def plot_semseg(img, semseg, ax):\n",
        "  v = Visualizer(img.permute(1,2,0), coco_metadata, scale=1.2, instance_mode=ColorMode.IMAGE_BW)\n",
        "  semantic_result = v.draw_sem_seg(semseg.cpu()).get_image()\n",
        "  ax.imshow(semantic_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "647cd32b",
      "metadata": {
        "id": "647cd32b"
      },
      "source": [
        "### 2.3  MultiMAE model setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4bd51fe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "767e11ba0ade4a14a5993996dd1b818c",
            "c6494a220fa140e2bfecdb290c06b040",
            "e2f78e9b0c934a1291c8ae26fdd72a5e",
            "6883913b3c5643748171823742f1ec8f",
            "50c25270286544008bc901a61a20829a",
            "567d153adc574b4e8c72c56b49387964",
            "21aa0fa877c5428fba5d61a93926dda1",
            "1ab0b48c8bff4b61b4a5ae0631c0ef0e",
            "21bcfdad2ee54413bad7833268a98199",
            "9405819b0aca4a97b4f704ef59c8bab9",
            "862038df210d4848866541013d13f363"
          ]
        },
        "id": "c4bd51fe",
        "outputId": "80c5a3b7-2202-400b-f60b-3cf806d5035a"
      },
      "outputs": [],
      "source": [
        "DOMAIN_CONF = {\n",
        "    'rgb': {\n",
        "        'input_adapter': partial(PatchedInputAdapter, num_channels=3, stride_level=1),\n",
        "        'output_adapter': partial(SpatialOutputAdapter, num_channels=3, stride_level=1),\n",
        "    },\n",
        "    'depth': {\n",
        "        'input_adapter': partial(PatchedInputAdapter, num_channels=1, stride_level=1),\n",
        "        'output_adapter': partial(SpatialOutputAdapter, num_channels=1, stride_level=1),\n",
        "    },\n",
        "    'semseg': {\n",
        "        'input_adapter': partial(SemSegInputAdapter, num_classes=133,\n",
        "                                 dim_class_emb=64, interpolate_class_emb=False, stride_level=4),\n",
        "        'output_adapter': partial(SpatialOutputAdapter, num_channels=133, stride_level=4),\n",
        "    },\n",
        "}\n",
        "DOMAINS = ['rgb', 'depth', 'semseg']\n",
        "\n",
        "input_adapters = {\n",
        "    domain: dinfo['input_adapter'](\n",
        "        patch_size_full=16,\n",
        "    )\n",
        "    for domain, dinfo in DOMAIN_CONF.items()\n",
        "}\n",
        "output_adapters = {\n",
        "    domain: dinfo['output_adapter'](\n",
        "        patch_size_full=16,\n",
        "        dim_tokens=256,\n",
        "        use_task_queries=True,\n",
        "        depth=2,\n",
        "        context_tasks=DOMAINS,\n",
        "        task=domain\n",
        "    )\n",
        "    for domain, dinfo in DOMAIN_CONF.items()\n",
        "}\n",
        "\n",
        "multimae = pretrain_multimae_base(\n",
        "    input_adapters=input_adapters,\n",
        "    output_adapters=output_adapters,\n",
        ")\n",
        "\n",
        "CKPT_URL = 'https://github.com/EPFL-VILAB/MultiMAE/releases/download/pretrained-weights/multimae-b_98_rgb+-depth-semseg_1600e_multivit-afff3f8c.pth'\n",
        "ckpt = torch.hub.load_state_dict_from_url(CKPT_URL, map_location='cpu')\n",
        "multimae.load_state_dict(ckpt['model'], strict=False)\n",
        "multimae = multimae.to(device).eval()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "uIv8bdqZ37fj",
        "qEAL1hmAkY-A",
        "ChHY7ibfkfTq",
        "647cd32b",
        "76d25ba6"
      ],
      "name": "MultiMAE Demo.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "flight",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "b5007674d9367f202903ad40bbfe5061e981a21fff3e651992d51e1cbbc95975"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1ab0b48c8bff4b61b4a5ae0631c0ef0e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21aa0fa877c5428fba5d61a93926dda1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21bcfdad2ee54413bad7833268a98199": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "50c25270286544008bc901a61a20829a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "567d153adc574b4e8c72c56b49387964": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6883913b3c5643748171823742f1ec8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9405819b0aca4a97b4f704ef59c8bab9",
            "placeholder": "â",
            "style": "IPY_MODEL_862038df210d4848866541013d13f363",
            "value": " 376M/376M [00:10&lt;00:00, 34.5MB/s]"
          }
        },
        "767e11ba0ade4a14a5993996dd1b818c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c6494a220fa140e2bfecdb290c06b040",
              "IPY_MODEL_e2f78e9b0c934a1291c8ae26fdd72a5e",
              "IPY_MODEL_6883913b3c5643748171823742f1ec8f"
            ],
            "layout": "IPY_MODEL_50c25270286544008bc901a61a20829a"
          }
        },
        "862038df210d4848866541013d13f363": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9405819b0aca4a97b4f704ef59c8bab9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6494a220fa140e2bfecdb290c06b040": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_567d153adc574b4e8c72c56b49387964",
            "placeholder": "â",
            "style": "IPY_MODEL_21aa0fa877c5428fba5d61a93926dda1",
            "value": "100%"
          }
        },
        "e2f78e9b0c934a1291c8ae26fdd72a5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ab0b48c8bff4b61b4a5ae0631c0ef0e",
            "max": 394406915,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_21bcfdad2ee54413bad7833268a98199",
            "value": 394406915
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
